# Deep Past - Neural Machine Translation
Deep Past Challenge 2025 Competetion organized by Kaggle.Task is to translate ancient Assyrian cuniform to english.
## My Solution
Fine-tuned a pretrained sequence-to-sequence Transformer based model with some text-preprocessing including sentence alligment.
## About the Model
Used Facebook's NLLB (No Language Left Behind),this variant is with 600 million parameters ideally made for machine translation and well suited for low-resource languages. For more information about the model click [here](https://huggingface.co/facebook/nllb-200-distilled-600M)
